{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaMdnwteWTzN3LQlAzSosN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudip234-source/PyTorch-Tutorial/blob/main/Quention_Answering_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Wff68-fdgs",
        "outputId": "f862946b-dae6-4c80-a496-37eaefa42cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                          question      answer\n",
              " 0                   What is the capital of France?       Paris\n",
              " 1                  What is the capital of Germany?      Berlin\n",
              " 2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              " 3  What is the largest planet in our solar system?     Jupiter\n",
              " 4   What is the boiling point of water in Celsius?         100,\n",
              " (90, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/100_Unique_QA_Dataset.csv')\n",
        "df.head(), df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "SnbPQYr4gdV6"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<UNK>':0}"
      ],
      "metadata": {
        "id": "g5j-TjtrhN0Z"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)\n"
      ],
      "metadata": {
        "id": "4vrV6Oz8jx_D"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "arqS0uVK6d_F",
        "outputId": "0c5de54f-9906-48bf-f360-1bd697f20db0"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaAtqdJskjp5",
        "outputId": "cbf209d8-e7f6-4851-ad66-4ce7ca4a82fa"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indeces(text,vocab):\n",
        "  indexed_text = []\n",
        "  for token in tokenize(text):\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "  return indexed_text"
      ],
      "metadata": {
        "id": "oHpx5B5qlAjP"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indeces(\"what is campusx\",vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8LuH0rjlxu4",
        "outputId": "55bf9ba1-365e-49df-b3d2-2c6f8624eff8"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "EPU3tT6Sl2vt"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(self,df,vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    numeric_qn = text_to_indeces(self.df.iloc[idx]['question'],self.vocab)\n",
        "    numeric_ans = text_to_indeces(self.df.iloc[idx]['answer'],self.vocab)\n",
        "    return torch.tensor(numeric_qn), torch.tensor(numeric_ans)"
      ],
      "metadata": {
        "id": "YBhKLxmrmrdY"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df,vocab)"
      ],
      "metadata": {
        "id": "PmydqimDonkG"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hVY0AcNot0K",
        "outputId": "749bc7ea-0a1a-4c6a-abbf-0aa396480b8a"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "w95JMAWVovvX"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for qn, ans in dataloader:\n",
        "  print(qn,ans)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5RcLQa5pE-N",
        "outputId": "5ac239a2-5947-4f9d-877e-8964f15f58a2"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp0LsVXVpLUt",
        "outputId": "d2f70e89-53e9-4af4-d681-1b66751ec9f1"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "IAIMQvxfqCUm"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myRNN(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super(myRNN,self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50,64,batch_first=True)\n",
        "    self.fc = nn.Linear(64,vocab_size)\n",
        "\n",
        "  def forward(self,question):\n",
        "    embedded_qn = self.embedding(question)\n",
        "    hidden,final_out = self.rnn(embedded_qn)\n",
        "    output = self.fc(final_out)\n",
        "    output = output.squeeze(0)\n",
        "    return output"
      ],
      "metadata": {
        "id": "YqzqzTHmq4dW"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[9][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3GmiIGbsr5K",
        "outputId": "3a6c9a86-6c92-47f6-cd33-cdaaa6dff899"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3, 50, 51, 19,  3, 45])"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(326,50)\n",
        "x(dataset[9][0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89vd4lzLsG8b",
        "outputId": "7215d947-3b4b-49d3-86ab-3c28b0608dff"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = x(dataset[9][0])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJMwxPHctjvb",
        "outputId": "b94b22c0-fc04-4ef5-c60b-f7ffa4543d7a"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.2636e-01, -2.5281e-01, -1.2102e+00,  8.7221e-01, -1.5227e+00,\n",
              "         -1.2963e-01, -8.4204e-01, -7.7837e-02, -6.8812e-01, -2.7064e-02,\n",
              "         -1.6626e-01, -8.3027e-02, -1.6697e-01,  1.4456e-01, -3.1724e-01,\n",
              "         -1.2725e+00,  1.9381e+00,  2.5518e-01,  8.4667e-01, -1.5931e+00,\n",
              "         -5.6445e-02, -2.2874e+00,  5.6804e-02,  7.0182e-01,  3.6714e-01,\n",
              "         -1.3882e-02,  5.0319e-03, -3.4336e-01,  5.8829e-01, -1.8760e-01,\n",
              "          3.5859e-02,  1.3459e-01,  9.1129e-01, -3.7251e-01, -1.2534e+00,\n",
              "         -2.8209e-01,  4.8890e-01,  7.4557e-01,  7.6829e-01, -3.0932e-01,\n",
              "         -2.0636e+00, -3.3635e-01,  1.1414e+00, -1.3551e+00,  6.2582e-01,\n",
              "          1.8467e+00,  4.0536e-01, -1.6026e+00, -8.7996e-01,  5.1704e-01],\n",
              "        [-5.1227e-01, -1.6821e-01,  6.7456e-01,  8.3289e-02,  9.9972e-02,\n",
              "         -3.7696e-01,  1.3546e+00, -5.2545e-01, -9.3383e-01, -6.1769e-01,\n",
              "         -1.2006e+00,  2.3678e-01,  4.9380e-01,  1.3077e+00,  1.6348e-01,\n",
              "         -3.1635e-01,  1.2430e+00,  2.0831e-02, -4.8667e-01,  1.0664e+00,\n",
              "         -9.3289e-01,  4.1839e-01,  1.4366e+00,  2.3371e-01, -5.5088e-01,\n",
              "         -2.0559e-01,  1.3054e-01, -1.3317e-01,  4.9155e-01,  4.1866e-01,\n",
              "          1.9858e-01,  1.9484e-01,  7.2451e-01, -5.1539e-01, -2.2431e-01,\n",
              "          1.2403e-01, -3.3685e-01, -1.2659e+00,  1.6257e+00,  4.4790e-01,\n",
              "          2.1708e-01,  9.8515e-01, -4.1084e-01,  1.0883e-01, -1.1094e-01,\n",
              "         -9.6561e-02, -2.3305e-01,  2.2582e-01, -2.5347e-01,  1.2800e+00],\n",
              "        [ 4.2563e-01, -1.9102e-01, -1.3133e+00,  4.8566e-01, -1.8502e-01,\n",
              "         -7.0952e-01,  9.4694e-01, -6.2118e-01,  5.4781e-01,  9.1202e-01,\n",
              "          5.1863e-01,  7.2676e-01, -1.6630e+00,  3.2790e-01,  4.2424e-01,\n",
              "          2.0537e-01, -2.4282e-01,  1.0764e-01,  5.2115e-01, -9.6080e-02,\n",
              "          6.0787e-02,  8.9830e-01, -3.4728e-01, -2.2354e-03, -1.0026e-01,\n",
              "         -1.8727e-01, -1.3074e+00, -1.0066e-01,  5.9215e-01,  7.2581e-01,\n",
              "          1.2088e+00,  8.0677e-01,  1.2678e+00, -5.3430e-01,  6.2949e-01,\n",
              "         -1.0428e+00, -2.2283e+00, -2.3174e+00, -4.3632e-01, -6.0902e-01,\n",
              "          3.4740e-01,  6.5851e-01, -1.0806e+00,  4.7170e-01, -3.4754e-01,\n",
              "         -4.1013e-01,  1.5015e+00, -1.5206e+00, -4.1320e-01, -1.8127e+00],\n",
              "        [ 2.6110e-02, -9.4096e-01, -2.7315e-01, -1.0970e+00,  4.8417e-02,\n",
              "         -1.2230e+00, -4.4029e-01,  5.8040e-01, -9.0261e-01, -6.2748e-01,\n",
              "          6.1054e-01, -2.0755e+00,  3.8372e-01, -1.1496e+00,  4.4802e-01,\n",
              "         -2.6276e-01,  1.5832e+00,  2.1870e+00, -1.0087e+00, -1.0851e+00,\n",
              "         -6.8085e-01,  1.4822e-01,  8.5592e-01, -5.3292e-01, -5.9072e-01,\n",
              "         -4.5792e-01,  1.6147e-01, -9.9195e-01,  5.6060e-01, -1.3468e+00,\n",
              "          3.7660e-01, -5.7235e-01, -1.4921e+00, -1.4453e+00,  2.3623e-01,\n",
              "          1.5028e+00,  1.7427e+00, -8.2350e-01,  1.4882e+00,  2.0086e-01,\n",
              "         -6.0224e-03,  1.8497e+00, -9.3533e-01, -4.2830e-01,  8.2814e-01,\n",
              "         -7.1555e-01, -9.6617e-02,  5.4037e-01,  6.2136e-01,  7.9619e-01],\n",
              "        [-1.8683e-01, -1.1937e+00,  1.2351e+00,  4.5462e-01,  1.1672e+00,\n",
              "         -1.2660e+00,  1.6254e-01,  7.7881e-01, -1.4882e-01,  6.1666e-01,\n",
              "          1.5886e+00, -2.3418e+00,  6.1780e-01, -1.6624e+00,  2.0915e+00,\n",
              "         -6.9010e-01, -8.7243e-01, -7.3072e-01,  5.0412e-01, -1.8521e-01,\n",
              "          1.2010e+00, -5.1072e-01, -8.0500e-01,  5.8697e-01, -6.7209e-01,\n",
              "         -5.8387e-02,  6.7267e-02,  2.1903e+00,  3.2418e-01,  1.3085e+00,\n",
              "         -1.7403e-01,  1.7658e+00,  1.2842e+00, -1.0710e+00,  9.5885e-01,\n",
              "         -3.1738e+00,  1.4078e-01, -6.2565e-01,  1.3007e-01,  9.9212e-01,\n",
              "          2.8127e-01, -6.0617e-02, -9.3920e-02,  6.9255e-01,  7.5373e-01,\n",
              "         -5.1422e-01,  1.2032e+00,  6.2894e-01,  4.4286e-01, -6.4771e-01],\n",
              "        [ 1.5753e+00,  2.6369e-01,  1.0864e+00,  1.3097e+00, -1.7864e+00,\n",
              "          6.7922e-01,  8.6551e-01, -2.3380e+00,  1.1415e-01,  1.7605e+00,\n",
              "         -7.1449e-01, -1.2143e-02,  8.4798e-02,  3.0569e-01,  1.0994e+00,\n",
              "          2.3563e-01,  2.2326e-01, -1.2715e+00, -1.8849e+00,  1.0644e-01,\n",
              "         -7.9901e-01,  8.4690e-01, -1.3305e-02, -6.9701e-01, -1.0625e+00,\n",
              "          2.9016e-01, -1.1649e+00,  3.8082e-01,  1.8220e+00,  8.3129e-01,\n",
              "         -4.3517e-01, -2.1211e-01, -3.1333e-01,  2.0783e-01, -1.0157e+00,\n",
              "         -7.3897e-01,  4.7071e-01, -9.8523e-02, -2.0418e-01, -1.5719e+00,\n",
              "         -5.5503e-01, -7.0660e-01,  3.5215e-01, -1.1451e+00,  2.9770e-02,\n",
              "         -1.1687e+00,  2.7728e-01, -2.5981e-01,  8.5501e-01, -3.6086e-01],\n",
              "        [ 4.2563e-01, -1.9102e-01, -1.3133e+00,  4.8566e-01, -1.8502e-01,\n",
              "         -7.0952e-01,  9.4694e-01, -6.2118e-01,  5.4781e-01,  9.1202e-01,\n",
              "          5.1863e-01,  7.2676e-01, -1.6630e+00,  3.2790e-01,  4.2424e-01,\n",
              "          2.0537e-01, -2.4282e-01,  1.0764e-01,  5.2115e-01, -9.6080e-02,\n",
              "          6.0787e-02,  8.9830e-01, -3.4728e-01, -2.2354e-03, -1.0026e-01,\n",
              "         -1.8727e-01, -1.3074e+00, -1.0066e-01,  5.9215e-01,  7.2581e-01,\n",
              "          1.2088e+00,  8.0677e-01,  1.2678e+00, -5.3430e-01,  6.2949e-01,\n",
              "         -1.0428e+00, -2.2283e+00, -2.3174e+00, -4.3632e-01, -6.0902e-01,\n",
              "          3.4740e-01,  6.5851e-01, -1.0806e+00,  4.7170e-01, -3.4754e-01,\n",
              "         -4.1013e-01,  1.5015e+00, -1.5206e+00, -4.1320e-01, -1.8127e+00],\n",
              "        [ 1.9766e+00, -8.3813e-01, -2.5980e+00,  1.4210e+00, -5.4248e-01,\n",
              "          1.7036e-01, -5.3601e-01,  2.4400e-01, -1.5867e+00, -1.0860e+00,\n",
              "         -3.9379e-01,  1.1658e+00, -2.6371e-02, -3.2203e-01, -1.0085e+00,\n",
              "         -8.2125e-01,  6.2264e-01,  9.4426e-01, -7.1788e-01,  3.7244e-01,\n",
              "          5.1043e-01,  4.2482e-01,  8.0254e-01, -6.1055e-01,  1.1728e+00,\n",
              "         -1.9297e+00, -4.4673e-01, -1.0704e+00,  1.2170e+00, -2.0959e+00,\n",
              "          4.0053e-01, -1.1787e+00,  8.1755e-01, -1.1214e+00,  5.3161e-01,\n",
              "          8.0609e-02,  6.9707e-02, -1.0837e+00,  1.6941e+00, -3.7222e-02,\n",
              "          1.2246e+00,  3.0467e-01, -1.0015e+00,  3.5288e-01,  4.9380e-01,\n",
              "         -2.4493e-01,  5.3898e-01, -5.1500e-01,  8.3915e-01, -2.2541e+00]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50,64)\n",
        "y(a)[0].shape #hidden state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vCUs9LTsYco",
        "outputId": "87fc756a-20f5-41cb-ef52-10c4b4c3588c"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = y(a)[1] # final output of RNN\n",
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWqYfI2rtxgB",
        "outputId": "027c4bfd-71e2-4787-863e-c1a2e4af5f84"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(64,326)\n",
        "z(b).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LVGSb9iuvtD",
        "outputId": "9c6d6949-2e33-49a0-9797-9f587931748c"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 326])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "XMRUJ5UUvlKc"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = myRNN(len(vocab))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "Mz2KYoCWy7N4"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for qn, ans in dataloader:\n",
        "    pred = model(qn)\n",
        "\n",
        "    loss = criterion(pred,ans[0])\n",
        "\n",
        "    optimizer.zero_grad\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss/len(dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHrdUiFozFNG",
        "outputId": "71f8269c-e504-4d26-88f6-b65799ded2dd"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 5.900683466593424\n",
            "Epoch: 2, Loss: 2.8149271097448136\n",
            "Epoch: 3, Loss: 0.6558932097680453\n",
            "Epoch: 4, Loss: 0.49696841312850465\n",
            "Epoch: 5, Loss: 0.4139556535026511\n",
            "Epoch: 6, Loss: 0.18219266300834533\n",
            "Epoch: 7, Loss: 0.30068978174939875\n",
            "Epoch: 8, Loss: 0.32678163155315093\n",
            "Epoch: 9, Loss: 0.4830453135975797\n",
            "Epoch: 10, Loss: 0.4392198399315027\n",
            "Epoch: 11, Loss: 0.5600269342296855\n",
            "Epoch: 12, Loss: 0.5974400406864052\n",
            "Epoch: 13, Loss: 0.603079562828261\n",
            "Epoch: 14, Loss: 0.7217928600128324\n",
            "Epoch: 15, Loss: 0.5265322950871005\n",
            "Epoch: 16, Loss: 1.3459121903385105\n",
            "Epoch: 17, Loss: 0.8847922889086157\n",
            "Epoch: 18, Loss: 0.7708152518590997\n",
            "Epoch: 19, Loss: 0.6675441623151415\n",
            "Epoch: 20, Loss: 0.906639703731077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_qn(model,question,threshold=0.5):\n",
        "  numerix_qn = text_to_indeces(question,vocab)\n",
        "  qn_tensor = torch.tensor(numerix_qn)\n",
        "  qn_tensor = qn_tensor.unsqueeze(0)\n",
        "  pred = model(qn_tensor)\n",
        "\n",
        "  probs = torch.nn.functional.softmax(pred,dim=1)\n",
        "  value , index = torch.max(probs,dim=1)\n",
        "  if value < threshold :\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index])"
      ],
      "metadata": {
        "id": "qHXlpshp0Srz"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_qn(model,'What is the capital of France?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWB4ldCQ20ne",
        "outputId": "9a9540d3-d2d5-4881-b173-f15554a20425"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paris\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mVshMmB27Ze"
      },
      "execution_count": 193,
      "outputs": []
    }
  ]
}